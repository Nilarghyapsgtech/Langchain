{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19271fc6",
   "metadata": {},
   "source": [
    "Recurssive Character Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb6423b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from pathlib import Path\n",
    "\n",
    "pdf_path=Path('./SRCs')\n",
    "\n",
    "docs=list(pdf_path.glob('*.pdf'))\n",
    "\n",
    "loader=PyPDFLoader(docs[0])\n",
    "\n",
    "docs=loader.load()\n",
    "\n",
    "splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=15,\n",
    "    length_function=len,\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \" \",\n",
    "        \".\",\n",
    "        \",\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "splits=splitter.split_documents(docs)\n",
    "print(len(splits))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5888594b",
   "metadata": {},
   "source": [
    "For Splitting Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c8e7331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "Chunk0\n",
      "*************************\n",
      "\n",
      "\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "\n",
      "\n",
      "*************************\n",
      "Chunk1\n",
      "*************************\n",
      "\n",
      "\n",
      "def subtract(a, b):\n",
      "    return a - b\n",
      "\n",
      "\n",
      "*************************\n",
      "Chunk2\n",
      "*************************\n",
      "\n",
      "\n",
      "def multiply(a, b):\n",
      "    return a * b\n",
      "\n",
      "\n",
      "*************************\n",
      "Chunk3\n",
      "*************************\n",
      "\n",
      "\n",
      "def divide(a, b):\n",
      "    if b == 0:\n",
      "\n",
      "\n",
      "*************************\n",
      "Chunk4\n",
      "*************************\n",
      "\n",
      "\n",
      "return \"Cannot divide by zero\"\n",
      "\n",
      "\n",
      "*************************\n",
      "Chunk5\n",
      "*************************\n",
      "\n",
      "\n",
      "return a / b\n",
      "\n",
      "\n",
      "*************************\n",
      "Chunk6\n",
      "*************************\n",
      "\n",
      "\n",
      "def modulus(a, b):\n",
      "    return a // b\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter,Language\n",
    "\n",
    "python_code='''\n",
    "\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract(a, b):\n",
    "    return a - b\n",
    "\n",
    "def multiply(a, b):\n",
    "    return a * b\n",
    "\n",
    "def divide(a, b):\n",
    "    if b == 0:\n",
    "        return \"Cannot divide by zero\"\n",
    "    return a / b\n",
    "\n",
    "def modulus(a, b):\n",
    "    return a // b\n",
    "\n",
    "    '''\n",
    "\n",
    "splitter=RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=5,\n",
    "\n",
    ")\n",
    "\n",
    "splits=splitter.split_text(python_code)\n",
    "for index,chunk in enumerate(splits):\n",
    "    print('*'*25)\n",
    "    print(f\"Chunk{index}\")\n",
    "    print('*'*25)\n",
    "    print('\\n')\n",
    "    print(chunk)\n",
    "    print('\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c781f0",
   "metadata": {},
   "source": [
    "HTML Recurssive Header Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d8ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "Chunk0\n",
      "*************************\n",
      "\n",
      "\n",
      "This is Heading 1 (Main Title)\n",
      "\n",
      "\n",
      "*************************\n",
      "Chunk1\n",
      "*************************\n",
      "\n",
      "\n",
      "Usually used for the main title of the page.\n",
      "\n",
      "\n",
      "*************************\n",
      "Chunk2\n",
      "*************************\n",
      "\n",
      "\n",
      "This is Heading 2 (Section Title)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "src_path='SRCs'\n",
    "html_path=list(Path(src_path).glob('*.html'))[0]\n",
    "html_content=''\n",
    "if Path(html_path).exists():\n",
    "    with open(html_path,'r',encoding='utf-8') as f:\n",
    "        html_content=f.read()\n",
    "else:\n",
    "    print(\"File Doesnot exists\")\n",
    "\n",
    "html_split_headings=[\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "\n",
    "]\n",
    "\n",
    "splitter=HTMLHeaderTextSplitter(headers_to_split_on=html_split_headings)\n",
    "splitted_text=splitter.split_text(html_content)\n",
    "\n",
    "for index,chunk in enumerate(splitted_text[:3]):\n",
    "    print('*'*25)\n",
    "    print(f\"Chunk{index}\")\n",
    "    print('*'*25)\n",
    "    print('\\n')\n",
    "    print(chunk.page_content)\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f9e2b2",
   "metadata": {},
   "source": [
    "JSON Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "54d22ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "Chunk0\n",
      "*************************\n",
      "\n",
      "\n",
      "{\"app\": {\"name\": \"Nebula\", \"version\": \"3.14.2\", \"environment\": \"production\", \"build\": {\"commit\": \"a9f3c2e1b7d8\", \"timestamp\": \"2026-01-10T18:42:11Z\", \"pipeline\": \"github-actions\"}}}\n",
      "\n",
      "\n",
      "*************************\n",
      "Chunk1\n",
      "*************************\n",
      "\n",
      "\n",
      "{\"users\": {\"0\": {\"id\": \"u_1001\", \"profile\": {\"username\": \"nightcoder\", \"email\": \"nightcoder@example.com\", \"created_at\": \"2024-06-11T09:12:45Z\", \"verified\": true, \"roles\": {\"0\": \"admin\", \"1\": \"developer\"}}}}}\n",
      "\n",
      "\n",
      "*************************\n",
      "Chunk2\n",
      "*************************\n",
      "\n",
      "\n",
      "{\"users\": {\"0\": {\"preferences\": {\"theme\": \"dark\", \"language\": \"en-US\", \"notifications\": {\"email\": true, \"sms\": false, \"push\": true}}, \"stats\": {\"logins\": 482, \"last_login\": \"2026-01-10T22:01:03Z\", \"projects_owned\": 12}}}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "json_path=list(Path('SRCs').glob('*.json'))[0]\n",
    "json_content=''\n",
    "if json_path.exists():\n",
    "    with open(json_path,'r',encoding='utf-8') as file:\n",
    "        json_content=json.load(file)\n",
    "\n",
    "splitter=RecursiveJsonSplitter(\n",
    "    max_chunk_size=300,\n",
    "    min_chunk_size=30\n",
    ")\n",
    "\n",
    "splitted_text=splitter.split_text(json_data=json_content,convert_lists=True)\n",
    "\n",
    "\n",
    "for index,chunk in enumerate(splitted_text[:3]):\n",
    "    print('*'*25)\n",
    "    print(f\"Chunk{index}\")\n",
    "    print('*'*25)\n",
    "    print('\\n')\n",
    "    print(chunk)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261e151",
   "metadata": {},
   "source": [
    "Token based Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff6cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "Chunk0\n",
      "*************************\n",
      "\n",
      "\n",
      "The cow is one of the most gentle, patient, and significant animals known to human civilization,\n",
      "playing a vital role in agriculture, economy, culture, and daily life across many societies for\n",
      "thousands of years. From ancient times, cows have been closely associated with human survival,\n",
      "providing essential resources such as milk, which is a primary source of nutrition containing\n",
      "proteins, calcium, vitamins, and healthy fats that support growth and overall well-being. Beyond\n",
      "milk, cows contribute\n",
      "\n",
      "\n",
      "*************************\n",
      "Chunk1\n",
      "*************************\n",
      "\n",
      "\n",
      " well-being. Beyond\n",
      "milk, cows contribute to the production of dairy products like curd, butter, cheese, and ghee, all of\n",
      "which form an important part of diets around the world. In rural economies, especially in agrarian\n",
      "societies, cows are often considered a backbone of livelihood, as they support farmers not only\n",
      "through dairy production but also through organic manure, which enriches soil fertility and promotes\n",
      "sustainable farming practices. The calm and non-aggressive\n",
      "\n",
      "\n",
      "*************************\n",
      "Chunk2\n",
      "*************************\n",
      "\n",
      "\n",
      "ustainable farming practices. The calm and non-aggressive nature of cows makes them easy to\n",
      "domesticate, and their presence on farms often symbolizes stability, patience, and harmony\n",
      "between humans and nature. Cows are also deeply embedded in cultural and religious traditions,\n",
      "particularly in countries like India, where they are regarded with respect and reverence, symbolizing\n",
      "motherhood, selfless giving, and abundance because they provide nourishment without asking for\n",
      "anything in return. This cultural importance has helped shape\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "txt_path=list(Path('SRCs').glob('*.txt'))[0]\n",
    "txt_content=''\n",
    "if txt_path.exists():\n",
    "    with open(txt_path,'r',encoding='utf-8') as file:\n",
    "        txt_content=file.read()\n",
    "\n",
    "splitter=TokenTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    encoding_name='cl100k_base'              #Used for gpt based models\n",
    ")\n",
    "\n",
    "splitted_text=splitter.split_text(txt_content)\n",
    "for index,chunk in enumerate(splitted_text[:3]):\n",
    "    print('*'*25)\n",
    "    print(f\"Chunk{index}\")\n",
    "    print('*'*25)\n",
    "    print('\\n')\n",
    "    print(chunk)\n",
    "    print('\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
